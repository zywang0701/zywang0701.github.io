---
title: "Paper Title Number New"
collection: publications
permalink: /publication/2015-10-01
excerpt: 'Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. 
This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward 
about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction
 model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model 
 is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine 
 learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal 
 aggregation weight for general machine-learning algorithms and demonstrate its improvement in the convergence rate. Our proposal can be seen as a 
 distributionally robust federated learning approach that is computationally efficient and easy to implement using arbitrary machine learning base algorithms, 
 satisfies some privacy constraints, and has a nice interpretation of different sources' importance for predicting a given target covariate distribution. 
 We demonstrate the performance of our proposed group distributionally robust method on simulated and real data with random forests and neural networks 
 as base-learning algorithms.'
date: 2015-10-01
venue: 'Journal 1'
paperurl: 'http://academicpages.github.io/files/paper3.pdf'
citation: 'Wang, Z., BÃ¼hlmann, P., & Guo, Z. (2023). Distributionally Robust Machine Learning with Multi-source Data. arXiv preprint arXiv:2309.02211.'
---

## Abstract 

Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. 
This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward 
about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction
 model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model 
 is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine 
 learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal 
 aggregation weight for general machine-learning algorithms and demonstrate its improvement in the convergence rate. Our proposal can be seen as a 
 distributionally robust federated learning approach that is computationally efficient and easy to implement using arbitrary machine learning base algorithms, 
 satisfies some privacy constraints, and has a nice interpretation of different sources' importance for predicting a given target covariate distribution. 
 We demonstrate the performance of our proposed group distributionally robust method on simulated and real data with random forests and neural networks 
 as base-learning algorithms.

[Download paper here](http://academicpages.github.io/files/paper3.pdf)

Recommended citation: Your Name, You. (2015). "Paper Title Number 3." <i>Journal 1</i>. 1(3).